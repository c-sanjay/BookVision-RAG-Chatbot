[
  {
    "id": "5f0f84ea-6e57-40a6-9f18-813ca76c65af_img_c1",
    "book_id": "5f0f84ea-6e57-40a6-9f18-813ca76c65af",
    "book_title": "Screenshot 2025-11-18 090821.png",
    "page": 1,
    "chunk_text": "Supporting technology Line of sight checks Tactical/Strategic Al Decision making Pathfinding (for complex enemies or bots) Movement Inverse kinematics or other constraints may limit possible movement"
  },
  {
    "id": "bd7a0cda-4578-4f14-b089-43dd510f514d_img_c1",
    "book_id": "bd7a0cda-4578-4f14-b089-43dd510f514d",
    "book_title": "Screenshot 2025-11-18 090821.png",
    "page": 1,
    "chunk_text": "Supporting technology Line of sight checks Tactical/Strategic Al Decision making Pathfinding (for complex enemies or bots) Movement Inverse kinematics or other constraints may limit possible movement"
  },
  {
    "id": "9e93a9b5-a934-42d8-b60f-6a43f9fd0011_img_c1",
    "book_id": "9e93a9b5-a934-42d8-b60f-6a43f9fd0011",
    "book_title": "Screenshot 2025-11-18 090821.png",
    "page": 1,
    "chunk_text": "Supporting technology Line of sight checks Tactical/Strategic Al Decision making Pathfinding (for complex enemies or bots) Movement Inverse kinematics or other constraints may limit possible movement"
  },
  {
    "id": "38ff9a3c-b62b-4c3f-b25e-fc72445198d9_img_c1",
    "book_id": "38ff9a3c-b62b-4c3f-b25e-fc72445198d9",
    "book_title": "Screenshot 2025-11-17 182246.png",
    "page": 1,
    "chunk_text": "Covariance hypothesis. One way of overcoming the limitation of Hebb\u2019s hypothesis is to use the covariance hypothesis introduced in Sejnowski (1977a, b). In this hypothesis, the presynaptic and postsynaptic signals in Eq. (2.9) are replaced by the departure of presynaptic and postsynaptic signals from their respective average values over a certain time interval. Let \u00a5 and y denote the time-averaged values of the presynaptic signal x, and postsynaptic signal y,, respectively. According to the covariance hypothesis, the adjustment applied to the synaptic weight w,, is defined by Awy = n(a; \u2014 X)(Ye ~ \u00a5) (2.10) where 1 is the learning-rate parameter. The average values x and y constitute presynaptic and postsynaptic thresholds, which determine the sign of synaptic modification. In particular, the covariance hypothesis allows for the following: Hebb\u2019s hypothesis wy slope = nx; Covariance slope = n(x)-\u00a5 Pe = 105) ypothesis Balance Postsynaptic point = 7 activity yy na, BF Maximum FIGURE 2.3 illustration of re = Hebb\u2019s hypothesis and the covariance hypothesis."
  },
  {
    "id": "9bd3832d-c805-4bc8-96b0-5ebcf4127609_img_c1",
    "book_id": "9bd3832d-c805-4bc8-96b0-5ebcf4127609",
    "book_title": "Screenshot 2025-11-17 182246.png",
    "page": 1,
    "chunk_text": "Covariance hypothesis. One way of overcoming the limitation of Hebb\u2019s hypothesis is to use the covariance hypothesis introduced in Sejnowski (1977a, b). In this hypothesis, the presynaptic and postsynaptic signals in Eq. (2.9) are replaced by the departure of presynaptic and postsynaptic signals from their respective average values over a certain time interval. Let \u00a5 and y denote the time-averaged values of the presynaptic signal x, and postsynaptic signal y,, respectively. According to the covariance hypothesis, the adjustment applied to the synaptic weight w,, is defined by Awy = n(a; \u2014 X)(Ye ~ \u00a5) (2.10) where 1 is the learning-rate parameter. The average values x and y constitute presynaptic and postsynaptic thresholds, which determine the sign of synaptic modification. In particular, the covariance hypothesis allows for the following: Hebb\u2019s hypothesis wy slope = nx; Covariance slope = n(x)-\u00a5 Pe = 105) ypothesis Balance Postsynaptic point = 7 activity yy na, BF Maximum FIGURE 2.3 illustration of re = Hebb\u2019s hypothesis and the covariance hypothesis."
  },
  {
    "id": "3f084ecd-ac8d-421b-b4fd-28679aaf50fe_img_c1",
    "book_id": "3f084ecd-ac8d-421b-b4fd-28679aaf50fe",
    "book_title": "Screenshot 2025-11-17 182246.png",
    "page": 1,
    "chunk_text": "Covariance hypothesis. One way of overcoming the limitation of Hebb\u2019s hypothesis is to use the covariance hypothesis introduced in Sejnowski (1977a, b). In this hypothesis, the presynaptic and postsynaptic signals in Eq. (2.9) are replaced by the departure of presynaptic and postsynaptic signals from their respective average values over a certain time interval. Let \u00a5 and y denote the time-averaged values of the presynaptic signal x, and postsynaptic signal y,, respectively. According to the covariance hypothesis, the adjustment applied to the synaptic weight w,, is defined by Awy = n(a; \u2014 X)(Ye ~ \u00a5) (2.10) where 1 is the learning-rate parameter. The average values x and y constitute presynaptic and postsynaptic thresholds, which determine the sign of synaptic modification. In particular, the covariance hypothesis allows for the following: Hebb\u2019s hypothesis wy slope = nx; Covariance slope = n(x)-\u00a5 Pe = 105) ypothesis Balance Postsynaptic point = 7 activity yy na, BF Maximum FIGURE 2.3 illustration of re = Hebb\u2019s hypothesis and the covariance hypothesis."
  },
  {
    "id": "ebfcf12a-9156-4abd-89c3-9a9b118872c8_img_c1",
    "book_id": "ebfcf12a-9156-4abd-89c3-9a9b118872c8",
    "book_title": "Screenshot 2025-11-16 121646.png",
    "page": 1,
    "chunk_text": "morphological analysis syntactic analysis semantic analysis pragmatic analysis t studies the structure of words and their meaningful parts (morphemes). Think of it as dissecting words to understand their roots, prefixes, and suffixes. This focuses on the arrangement of words and phrases to create well-formed sentences. It's all about grammar and sentence structure. This delves into the meanings of words, phrases, and sentences. It ensures that the text makes sense and the meaning is clear. This considers context and the intended meaning behind the words. It's about understanding language use in real-world scenarios."
  },
  {
    "id": "0b24ed68-65d9-4826-9ee9-d022fa8320c4_img_c1",
    "book_id": "0b24ed68-65d9-4826-9ee9-d022fa8320c4",
    "book_title": "Screenshot 2025-11-16 121646.png",
    "page": 1,
    "chunk_text": "morphological analysis syntactic analysis semantic analysis pragmatic analysis t studies the structure of words and their meaningful parts (morphemes). Think of it as dissecting words to understand their roots, prefixes, and suffixes. This focuses on the arrangement of words and phrases to create well-formed sentences. It's all about grammar and sentence structure. This delves into the meanings of words, phrases, and sentences. It ensures that the text makes sense and the meaning is clear. This considers context and the intended meaning behind the words. It's about understanding language use in real-world scenarios."
  },
  {
    "id": "01dca0f3-bf99-44fa-9043-ee38befab68c_img_c1",
    "book_id": "01dca0f3-bf99-44fa-9043-ee38befab68c",
    "book_title": "Screenshot 2025-11-16 121646.png",
    "page": 1,
    "chunk_text": "morphological analysis syntactic analysis semantic analysis pragmatic analysis t studies the structure of words and their meaningful parts (morphemes). Think of it as dissecting words to understand their roots, prefixes, and suffixes. This focuses on the arrangement of words and phrases to create well-formed sentences. It's all about grammar and sentence structure. This delves into the meanings of words, phrases, and sentences. It ensures that the text makes sense and the meaning is clear. This considers context and the intended meaning behind the words. It's about understanding language use in real-world scenarios."
  },
  {
    "id": "f643168f-2681-48be-9233-2def50b0e789_img_c1",
    "book_id": "f643168f-2681-48be-9233-2def50b0e789",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 1,
    "chunk_text": "These methods rely on statistical tests to constraint- determine the independence relationships based between variables. The structure is built methods by testing conditional independence and adding edges based on the results hese methods assign a score to different score- structures based on how well they explain based the data. Common scoring methods include methods Bayesian Information Criterion (BIC) and Akaike Information Criterion (AIC). This is a popular method for parameter expectation- learning in the presence of hidden maximization variables. The EM algorithm consists of (em) algorithm two steps: E-step (Expectation) and Mstep (Maximization) maximum This approach estimates parameters by likelihood maximizing the likelihood of the observed estimation data. However, with hidden variables, (mle) direct computation can be challenging. This involves determining the network struct leoning structure itself, which includes identifying 9 which variables are connected and how. his involves estimating the conditional parameter probability distributions (CPDs) for the learning observed and hidden variables given the structure of the network."
  },
  {
    "id": "56f00ab6-df8c-4dd0-8a80-e503b63f44fb_img_c1",
    "book_id": "56f00ab6-df8c-4dd0-8a80-e503b63f44fb",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 1,
    "chunk_text": "These methods rely on statistical tests to constraint- determine the independence relationships based between variables. The structure is built methods by testing conditional independence and adding edges based on the results hese methods assign a score to different score- structures based on how well they explain based the data. Common scoring methods include methods Bayesian Information Criterion (BIC) and Akaike Information Criterion (AIC). This is a popular method for parameter expectation- learning in the presence of hidden maximization variables. The EM algorithm consists of (em) algorithm two steps: E-step (Expectation) and Mstep (Maximization) maximum This approach estimates parameters by likelihood maximizing the likelihood of the observed estimation data. However, with hidden variables, (mle) direct computation can be challenging. This involves determining the network struct leoning structure itself, which includes identifying 9 which variables are connected and how. his involves estimating the conditional parameter probability distributions (CPDs) for the learning observed and hidden variables given the structure of the network."
  },
  {
    "id": "0a3de980-7864-4bbd-a18e-f74605cf75d0_img_c1",
    "book_id": "0a3de980-7864-4bbd-a18e-f74605cf75d0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 1,
    "chunk_text": "These methods rely on statistical tests to constraint- determine the independence relationships based between variables. The structure is built methods by testing conditional independence and adding edges based on the results hese methods assign a score to different score- structures based on how well they explain based the data. Common scoring methods include methods Bayesian Information Criterion (BIC) and Akaike Information Criterion (AIC). This is a popular method for parameter expectation- learning in the presence of hidden maximization variables. The EM algorithm consists of (em) algorithm two steps: E-step (Expectation) and Mstep (Maximization) maximum This approach estimates parameters by likelihood maximizing the likelihood of the observed estimation data. However, with hidden variables, (mle) direct computation can be challenging. This involves determining the network struct leoning structure itself, which includes identifying 9 which variables are connected and how. his involves estimating the conditional parameter probability distributions (CPDs) for the learning observed and hidden variables given the structure of the network."
  },
  {
    "id": "9694df87-3b38-4fa4-b9af-71556c89eef9_img_c1",
    "book_id": "9694df87-3b38-4fa4-b9af-71556c89eef9",
    "book_title": "Screenshot 2025-11-12 192509.png",
    "page": 1,
    "chunk_text": "axioms of Utility theory in detail with Utility function. Mention 5 Von Neumann Morgenstein Axioms 1. Completeness 2. Continuity 3. Independence 4. Transitivity 5. Decomposability"
  },
  {
    "id": "5d93932c-32cc-4cc3-aaab-eb53580b20d0_img_c1",
    "book_id": "5d93932c-32cc-4cc3-aaab-eb53580b20d0",
    "book_title": "Screenshot 2025-11-12 192509.png",
    "page": 1,
    "chunk_text": "axioms of Utility theory in detail with Utility function. Mention 5 Von Neumann Morgenstein Axioms 1. Completeness 2. Continuity 3. Independence 4. Transitivity 5. Decomposability"
  },
  {
    "id": "de0e3b8f-c648-443a-8abe-4cab39cdbcd8_img_c1",
    "book_id": "de0e3b8f-c648-443a-8abe-4cab39cdbcd8",
    "book_title": "Screenshot 2025-11-12 192509.png",
    "page": 1,
    "chunk_text": "axioms of Utility theory in detail with Utility function. Mention 5 Von Neumann Morgenstein Axioms 1. Completeness 2. Continuity 3. Independence 4. Transitivity 5. Decomposability"
  },
  {
    "id": "6f2fb481-e384-4534-95f6-01b6cd6f2672_img_c1",
    "book_id": "6f2fb481-e384-4534-95f6-01b6cd6f2672",
    "book_title": "Screenshot 2025-11-14 125418.png",
    "page": 1,
    "chunk_text": "Creating a Bar Chart with Seaborn: The barplot() function in Seaborn is used to create bar charts, The xandy arguments represent the categories and the values, respectively. barplot(): \u2018The barplot() function in seaborn has several parameters that you can use to customize the appearance and behavior of the bar plot. Here are some commonly used parameters: X.Y! The variables to be plotted on the x and y axes, respectively. These can be column names from a DataFrame, arrays, or lists of values The DataF rame or long-form data object that contains the data to be plotted. hue: Grouping variable that will produce bars with different colors. This parameter is useful when you want to differentiate the bars based on another categorical variable. palette: The color palette to be used for coloring the bars. It can be a predefined palette name, a list of colors, or a seaborn color palette object. estimator: The function to aggregate the values of the y variable at each x level. The default is mean, but other common options include sum, median, count, ete. Gi! The size of the confidence interval to draw around the estimated values. By default, it is set to sd, which draws a confidence interval corresponding to the standard deviation. the width of the caps on error bars in pixels. order: The order to plot the categorical levels of the x variable. It can be a list of values or a seaborn categorical ordering object. orient: The orientation of the plot. By default, it is set to 'v' for vertical orientation. You can set it to 'h for horizontal orientation. x: The matplotlib Axes object to draw the plot onto. If None. the current Axes will be used."
  },
  {
    "id": "054bf58c-c7e8-4733-ba86-e2c0343ede9b_img_c1",
    "book_id": "054bf58c-c7e8-4733-ba86-e2c0343ede9b",
    "book_title": "Screenshot 2025-11-14 125418.png",
    "page": 1,
    "chunk_text": "Creating a Bar Chart with Seaborn: The barplot() function in Seaborn is used to create bar charts, The xandy arguments represent the categories and the values, respectively. barplot(): \u2018The barplot() function in seaborn has several parameters that you can use to customize the appearance and behavior of the bar plot. Here are some commonly used parameters: X.Y! The variables to be plotted on the x and y axes, respectively. These can be column names from a DataFrame, arrays, or lists of values The DataF rame or long-form data object that contains the data to be plotted. hue: Grouping variable that will produce bars with different colors. This parameter is useful when you want to differentiate the bars based on another categorical variable. palette: The color palette to be used for coloring the bars. It can be a predefined palette name, a list of colors, or a seaborn color palette object. estimator: The function to aggregate the values of the y variable at each x level. The default is mean, but other common options include sum, median, count, ete. Gi! The size of the confidence interval to draw around the estimated values. By default, it is set to sd, which draws a confidence interval corresponding to the standard deviation. the width of the caps on error bars in pixels. order: The order to plot the categorical levels of the x variable. It can be a list of values or a seaborn categorical ordering object. orient: The orientation of the plot. By default, it is set to 'v' for vertical orientation. You can set it to 'h for horizontal orientation. x: The matplotlib Axes object to draw the plot onto. If None. the current Axes will be used."
  },
  {
    "id": "7768734e-8d90-49f8-bd58-1f4a1fdd9e17_img_c1",
    "book_id": "7768734e-8d90-49f8-bd58-1f4a1fdd9e17",
    "book_title": "Screenshot 2025-11-14 125418.png",
    "page": 1,
    "chunk_text": "Creating a Bar Chart with Seaborn: The barplot() function in Seaborn is used to create bar charts, The xandy arguments represent the categories and the values, respectively. barplot(): \u2018The barplot() function in seaborn has several parameters that you can use to customize the appearance and behavior of the bar plot. Here are some commonly used parameters: X.Y! The variables to be plotted on the x and y axes, respectively. These can be column names from a DataFrame, arrays, or lists of values The DataF rame or long-form data object that contains the data to be plotted. hue: Grouping variable that will produce bars with different colors. This parameter is useful when you want to differentiate the bars based on another categorical variable. palette: The color palette to be used for coloring the bars. It can be a predefined palette name, a list of colors, or a seaborn color palette object. estimator: The function to aggregate the values of the y variable at each x level. The default is mean, but other common options include sum, median, count, ete. Gi! The size of the confidence interval to draw around the estimated values. By default, it is set to sd, which draws a confidence interval corresponding to the standard deviation. the width of the caps on error bars in pixels. order: The order to plot the categorical levels of the x variable. It can be a list of values or a seaborn categorical ordering object. orient: The orientation of the plot. By default, it is set to 'v' for vertical orientation. You can set it to 'h for horizontal orientation. x: The matplotlib Axes object to draw the plot onto. If None. the current Axes will be used."
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c0",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 1,
    "chunk_text": "These methods rely on statistical tests to"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c1",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 2,
    "chunk_text": "constraint- determine the independence relationships"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c2",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 3,
    "chunk_text": "based between variables. The structure is built"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c3",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 4,
    "chunk_text": "methods by testing conditional independence and"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c4",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 5,
    "chunk_text": "adding edges based on the results"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c5",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 6,
    "chunk_text": "hese methods assign a score to different"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c6",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 7,
    "chunk_text": "score- structures based on how well they explain"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c7",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 8,
    "chunk_text": "based the data. Common scoring methods include"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c8",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 9,
    "chunk_text": "methods Bayesian Information Criterion (BIC) and"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c9",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 10,
    "chunk_text": "Akaike Information Criterion (AIC)."
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c10",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 11,
    "chunk_text": "This is a popular method for parameter"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c11",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 12,
    "chunk_text": "expectation- learning in the presence of hidden"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c12",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 13,
    "chunk_text": "maximization variables. The EM algorithm consists of"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c13",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 14,
    "chunk_text": "(em) algorithm two steps: E-step (Expectation) and M-"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c14",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 15,
    "chunk_text": "step (Maximization)"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c15",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 16,
    "chunk_text": "maximum This approach estimates parameters by"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c16",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 17,
    "chunk_text": "likelihood maximizing the likelihood of the observed"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c17",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 18,
    "chunk_text": "estimation data. However, with hidden variables,"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c18",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 19,
    "chunk_text": "(mle) direct computation can be challenging."
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c19",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 20,
    "chunk_text": "This involves determining the network"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c20",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 21,
    "chunk_text": "struct"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c21",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 22,
    "chunk_text": "leoning structure itself, which includes identifying"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c22",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 23,
    "chunk_text": "9 which variables are connected and how."
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c23",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 24,
    "chunk_text": "his involves estimating the conditional"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c24",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 25,
    "chunk_text": "parameter probability distributions (CPDs) for the"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c25",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 26,
    "chunk_text": "learning observed and hidden variables given the"
  },
  {
    "id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059_c26",
    "book_id": "2c5dca2f-dfcd-44fd-9f86-bced87c3b059",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 27,
    "chunk_text": "structure of the network."
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c0",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 1,
    "chunk_text": "These methods rely on statistical tests to"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c1",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 2,
    "chunk_text": "constraint- determine the independence relationships"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c2",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 3,
    "chunk_text": "based between variables. The structure is built"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c3",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 4,
    "chunk_text": "methods by testing conditional independence and"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c4",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 5,
    "chunk_text": "adding edges based on the results"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c5",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 6,
    "chunk_text": "hese methods assign a score to different"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c6",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 7,
    "chunk_text": "score- structures based on how well they explain"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c7",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 8,
    "chunk_text": "based the data. Common scoring methods include"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c8",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 9,
    "chunk_text": "methods Bayesian Information Criterion (BIC) and"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c9",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 10,
    "chunk_text": "Akaike Information Criterion (AIC)."
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c10",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 11,
    "chunk_text": "This is a popular method for parameter"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c11",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 12,
    "chunk_text": "expectation- learning in the presence of hidden"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c12",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 13,
    "chunk_text": "maximization variables. The EM algorithm consists of"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c13",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 14,
    "chunk_text": "(em) algorithm two steps: E-step (Expectation) and M-"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c14",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 15,
    "chunk_text": "step (Maximization)"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c15",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 16,
    "chunk_text": "maximum This approach estimates parameters by"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c16",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 17,
    "chunk_text": "likelihood maximizing the likelihood of the observed"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c17",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 18,
    "chunk_text": "estimation data. However, with hidden variables,"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c18",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 19,
    "chunk_text": "(mle) direct computation can be challenging."
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c19",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 20,
    "chunk_text": "This involves determining the network"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c20",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 21,
    "chunk_text": "struct"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c21",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 22,
    "chunk_text": "leoning structure itself, which includes identifying"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c22",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 23,
    "chunk_text": "9 which variables are connected and how."
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c23",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 24,
    "chunk_text": "his involves estimating the conditional"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c24",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 25,
    "chunk_text": "parameter probability distributions (CPDs) for the"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c25",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 26,
    "chunk_text": "learning observed and hidden variables given the"
  },
  {
    "id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c_c26",
    "book_id": "d57b7a2e-e5b2-4010-bd3a-7c45fb97ef6c",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 27,
    "chunk_text": "structure of the network."
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c0",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 1,
    "chunk_text": "These methods rely on statistical tests to"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c1",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 2,
    "chunk_text": "constraint- determine the independence relationships"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c2",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 3,
    "chunk_text": "based between variables. The structure is built"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c3",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 4,
    "chunk_text": "methods by testing conditional independence and"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c4",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 5,
    "chunk_text": "adding edges based on the results"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c5",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 6,
    "chunk_text": "hese methods assign a score to different"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c6",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 7,
    "chunk_text": "score- structures based on how well they explain"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c7",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 8,
    "chunk_text": "based the data. Common scoring methods include"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c8",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 9,
    "chunk_text": "methods Bayesian Information Criterion (BIC) and"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c9",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 10,
    "chunk_text": "Akaike Information Criterion (AIC)."
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c10",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 11,
    "chunk_text": "This is a popular method for parameter"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c11",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 12,
    "chunk_text": "expectation- learning in the presence of hidden"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c12",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 13,
    "chunk_text": "maximization variables. The EM algorithm consists of"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c13",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 14,
    "chunk_text": "(em) algorithm two steps: E-step (Expectation) and M-"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c14",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 15,
    "chunk_text": "step (Maximization)"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c15",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 16,
    "chunk_text": "maximum This approach estimates parameters by"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c16",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 17,
    "chunk_text": "likelihood maximizing the likelihood of the observed"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c17",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 18,
    "chunk_text": "estimation data. However, with hidden variables,"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c18",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 19,
    "chunk_text": "(mle) direct computation can be challenging."
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c19",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 20,
    "chunk_text": "This involves determining the network"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c20",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 21,
    "chunk_text": "struct"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c21",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 22,
    "chunk_text": "leoning structure itself, which includes identifying"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c22",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 23,
    "chunk_text": "9 which variables are connected and how."
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c23",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 24,
    "chunk_text": "his involves estimating the conditional"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c24",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 25,
    "chunk_text": "parameter probability distributions (CPDs) for the"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c25",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 26,
    "chunk_text": "learning observed and hidden variables given the"
  },
  {
    "id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa_c26",
    "book_id": "0ff90fc1-b6ea-4b11-9e46-df347c67b4fa",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 27,
    "chunk_text": "structure of the network."
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c0",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 1,
    "chunk_text": "These methods rely on statistical tests to"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c1",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 2,
    "chunk_text": "constraint- determine the independence relationships"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c2",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 3,
    "chunk_text": "based between variables. The structure is built"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c3",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 4,
    "chunk_text": "methods by testing conditional independence and"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c4",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 5,
    "chunk_text": "adding edges based on the results"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c5",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 6,
    "chunk_text": "hese methods assign a score to different"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c6",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 7,
    "chunk_text": "score- structures based on how well they explain"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c7",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 8,
    "chunk_text": "based the data. Common scoring methods include"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c8",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 9,
    "chunk_text": "methods Bayesian Information Criterion (BIC) and"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c9",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 10,
    "chunk_text": "Akaike Information Criterion (AIC)."
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c10",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 11,
    "chunk_text": "This is a popular method for parameter"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c11",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 12,
    "chunk_text": "expectation- learning in the presence of hidden"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c12",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 13,
    "chunk_text": "maximization variables. The EM algorithm consists of"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c13",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 14,
    "chunk_text": "(em) algorithm two steps: E-step (Expectation) and M-"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c14",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 15,
    "chunk_text": "step (Maximization)"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c15",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 16,
    "chunk_text": "maximum This approach estimates parameters by"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c16",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 17,
    "chunk_text": "likelihood maximizing the likelihood of the observed"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c17",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 18,
    "chunk_text": "estimation data. However, with hidden variables,"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c18",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 19,
    "chunk_text": "(mle) direct computation can be challenging."
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c19",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 20,
    "chunk_text": "This involves determining the network"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c20",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 21,
    "chunk_text": "struct"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c21",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 22,
    "chunk_text": "leoning structure itself, which includes identifying"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c22",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 23,
    "chunk_text": "9 which variables are connected and how."
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c23",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 24,
    "chunk_text": "his involves estimating the conditional"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c24",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 25,
    "chunk_text": "parameter probability distributions (CPDs) for the"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c25",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 26,
    "chunk_text": "learning observed and hidden variables given the"
  },
  {
    "id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0_c26",
    "book_id": "0f94bc3b-4b7d-40d2-9229-aa93691274f0",
    "book_title": "Screenshot 2025-11-16 123525.png",
    "page": 27,
    "chunk_text": "structure of the network."
  }
]